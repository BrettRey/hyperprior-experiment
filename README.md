# Hyperprior Experiment

Bridging the attention-bias hypothesis (Reynolds 2026) with inductive bias distillation (McCoy & Griffiths 2025).

**Core idea:** Replace their complex meta-learning distillation (MAML) with a simpler "gain scalar k" approach -- a precision boost on tokens satisfying hierarchical rhythm criteria -- to achieve the same recursive competence.

**Parent paper:** `papers/echolocation/` (Reynolds 2026, submitted to ELT)
